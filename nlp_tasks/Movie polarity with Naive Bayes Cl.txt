Movie Polarity with Naive Bayes Classifier

В этом задании вам нужно реализовать собственный наивный байесовский классификатор для автоматического определения общей тональности (положительная или отрицательная) англоязычных отзывов о фильмах.

Я предоставляю вам данные для обучения: файл с положительными отзывами (pos_train.txt) и файл с отрицательными отзывами (neg_train.txt). Данные адаптированы отсюда:

http://www.cs.cornell.edu/people/pabo/movie-review-data/

Это реальные отзывы пользователей imdb.com, прошедшие элементарную предобработку (токенизация, разбивка на предложения). В обоих файлах по 700 отзывов.

Задание 1. Составьте свой список англоязычной положительной и отрицательной лексики. Количество положительных и отрицательных слов может быть разным. Пример: good, bad, liked, hated. Объем списка - не менее 50 слов.

Небольшой намёк: список можно набирать разными способами... 

Задание 2. Для реализации классификатора необходимо написать следующие функции:


def extract_features(text, features):
    Извлечение признаков. "Превращает" текст в вектор (список) признаков, т.е. чисел. Каждая позиция в списке - количество вхождений соответствующего слова из списка features в тексте text.
	Вход: text (строка), features (список слов)
	Выход: список целых чисел
    
    
def train_nbc(features, corpora):
	Эта функция собственно "обучает" классификатор на корпусах. Необходимо посчитать параметры для двух моделей: модель положительных отзывов и модель отрицательных отзывов, на двух соответствующих корпусах. Другими словами, в одном списке должно быть два вложенных списка параметров, каждый длиной n, где n - количество признаков (слов). Каждый параметр считается так: количество вхождений соответствующего признака (слова) в соответствующем корпусе (положительном, когда строим первую модель, и отрицательном, когда строим вторую), делённое на суммарное количество вхождений всех признаков в данном корпусе.
	Важно! При обучении желательно использовать сглаживание. Без сглаживания классификатор будет работать плохо. Стоит ему один раз увидеть в тексте признак, который ни разу не встречался в обучающей выборке для одного из классов, как классификатор "обнулит" весь результат для данного класса, независимо от того, какие остальные признаки были обнаружены в тексте. Чтобы избежать этого досадного недоразумения, реализуем простое, но эффективное сглаживание "Плюс-1" (Add-1 smoothing). То есть для каждого корпуса мы сначала считаем реальные частоты для каждого признака, потом делаем сглаживание (все частоты прибавляются на 1), а уже после этого вычисляем параметры по формуле, приведённой в предыдущем абзаце.
	Вход: features (список слов-признаков), corpora (список из двух корпусов, т.е. строк), classes (список из двух строк, обозначающих классы, напр. ['positive', 'negative'], в том же порядке, в котором идут "положительный" и "отрицательный" корпуса.
	Выход: список списков (два списка чисел-параметров внутри одного списка)
    
    
def classify(text, features, classes, priors, Params):
	Самая главная функция. Для каждого класса считает произведение вероятностей: вероятность класса (или prior) * вероятность каждого слова-признака для данного класса, возведённая в степень k, где k - абсолютная частота данного слова В АНАЛИЗИРУЕМОМ ТЕКСТЕ (а не в корпусе). 
	Вероятность класса в данной задаче одинакова для обоих классов и составляет 0.5 (т.к. у нас одинаковое количество текстов обоих классов). 
	Вероятность каждого слова-признака для каждого класса берётся из списка списков Params, который мы формировали ранее с помощью функции train_nbc.
	После всех подсчётов функция "присваивает" анализируемому тексту тот класс, для которого произведение вероятностей получилось больше.
	Вход: text (строка - анализируемый текст, который классификатор раньше не видел), features (список слов-признаков), classes (список из двух строк, обозначающих классы), priors (список из вероятностей каждого класса, в данном случае [0.5, 0.5]), Params (два списка чисел-параметров внутри одного списка).
	Выход: строка, соответствующая названию класса, "выбранного" классификатором для анализируемого текста.

    
Вот вспомогательный код, который должен идти после определения всех трёх функций:

corpus_pos = open('pos_train.txt', encoding='utf-8').read()
corpus_neg = open('neg_train.txt', encoding='utf-8').read()
corpora = corpus_pos, corpus_neg
classes = 'positive', 'negative'
Params = train_nbc(features, corpora, classes)
priors = 0.5, 0.5
text1 = 'The movie was horrible, it was absolutely awful.'
label1 = classify(text1, features, classes, priors, Params)
text2 = 'I really enjoyed the film, it was fantastic.'
label2 = classify(text2, features, classes, priors, Params)
print(label1, label2)  # ожидаемый вывод программы: negative positive

Желаю успехов!